---
phase: 04-quality-instrumentation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scraper.py
autonomous: true

must_haves:
  truths:
    - "User can see how many leads were processed at end of run"
    - "User can see how many leads qualified vs rejected"
    - "User can see top rejection reasons by count"
    - "User can see qualification tier distribution"
  artifacts:
    - path: "scraper.py"
      provides: "FilterStats dataclass and print_filter_stats function"
      contains: "class FilterStats"
    - path: "scraper.py"
      provides: "Stats collection in scrape_solar_jobs"
      contains: "stats.add_qualified"
  key_links:
    - from: "scrape_solar_jobs()"
      to: "FilterStats"
      via: "stats collection during filtering"
      pattern: "stats\\.(add_qualified|add_rejected)"
    - from: "main()"
      to: "print_filter_stats()"
      via: "stats output at end of run"
      pattern: "print_filter_stats\\(stats\\)"
---

<objective>
Add per-rule statistics logging to the solar lead scraper (QUAL-01).

Purpose: Enable understanding of filter behavior through aggregated statistics - how many leads pass/fail, which rejection reasons are most common, and which tiers are producing qualified leads.

Output: FilterStats dataclass, stats collection in scrape_solar_jobs(), and print_filter_stats() function displaying human-readable statistics at end of each run.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-quality-instrumentation/04-RESEARCH.md

# Key existing code
@scraper.py (ScoringResult dataclass, score_job function, scrape_solar_jobs function)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add FilterStats dataclass</name>
  <files>scraper.py</files>
  <action>
Add FilterStats dataclass near ScoringResult (around line 35). Use Counter from collections for aggregation.

```python
from collections import Counter

@dataclass
class FilterStats:
    """Statistics collected during a filter run.

    Attributes:
        total_processed: Total leads processed
        total_qualified: Leads that passed filter
        total_rejected: Leads that failed filter
        rejection_categories: Counter of rejection reason categories
        qualification_tiers: Counter of highest tier matched for qualifications
        company_blocked: Count of company blocklist rejections
    """
    total_processed: int = 0
    total_qualified: int = 0
    total_rejected: int = 0
    rejection_categories: Counter = field(default_factory=Counter)
    qualification_tiers: Counter = field(default_factory=Counter)
    company_blocked: int = 0

    def add_qualified(self, tier: str) -> None:
        """Record a qualified lead."""
        self.total_processed += 1
        self.total_qualified += 1
        self.qualification_tiers[tier] += 1

    def add_rejected(self, category: str, is_company_blocked: bool = False) -> None:
        """Record a rejected lead."""
        self.total_processed += 1
        self.total_rejected += 1
        self.rejection_categories[category] += 1
        if is_company_blocked:
            self.company_blocked += 1

    @property
    def pass_rate(self) -> float:
        """Calculate pass rate as percentage."""
        if self.total_processed == 0:
            return 0.0
        return self.total_qualified / self.total_processed * 100
```

Add `from collections import Counter` to imports at top of file.

Category normalization: Map full reason strings to config section names for aggregation:
- "Company '...' in blocklist" -> "company_blocklist"
- "Excluded: ..." with installer patterns -> "exclusions.installer"
- "Excluded: ..." with utility patterns -> "exclusions.utility"
- "Excluded: ..." with EDA patterns -> "exclusions.eda_tools"
- "Missing required solar/PV context" -> "no_solar_context"
- Score < threshold -> "below_threshold"
  </action>
  <verify>
Run Python syntax check:
```bash
python -c "from scraper import FilterStats; s = FilterStats(); s.add_qualified('tier1'); print(s.total_qualified)"
```
Should print `1` with no errors.
  </verify>
  <done>FilterStats dataclass exists with add_qualified(), add_rejected(), and pass_rate property.</done>
</task>

<task type="auto">
  <name>Task 2: Collect stats in scrape_solar_jobs</name>
  <files>scraper.py</files>
  <action>
Modify scrape_solar_jobs() to collect FilterStats during filtering. The function currently uses description_matches() which returns bool. We need to call score_job() directly to get ScoringResult with reasons.

Replace the filter section (around line 433-436) that does:
```python
df = df[df.apply(lambda row: description_matches(row['description'], row.get('company')), axis=1)]
```

With stats collection:
```python
# Collect filter statistics
stats = FilterStats()
qualified_mask = []

for idx, row in df.iterrows():
    result = score_job(row['description'], row.get('company'))

    if result.qualified:
        # Extract tier from first positive reason
        tier = "unknown"
        for reason in result.reasons:
            if reason.startswith("+") and "tier" not in reason.lower():
                # Parse tier from reason like "+100: Tier 1 solar tool"
                if "Tier 1" in reason or "tier1" in reason.lower():
                    tier = "tier1"
                elif "Tier 2" in reason or "tier2" in reason.lower():
                    tier = "tier2"
                elif "Tier 3" in reason or "tier3" in reason.lower():
                    tier = "tier3"
                elif "Tier 4" in reason or "tier4" in reason.lower():
                    tier = "tier4"
                elif "Tier 5" in reason or "tier5" in reason.lower():
                    tier = "tier5"
                elif "Tier 6" in reason or "tier6" in reason.lower():
                    tier = "tier6"
                break
        stats.add_qualified(tier)
        qualified_mask.append(True)
    else:
        # Categorize rejection
        category = categorize_rejection(result)
        is_blocked = result.company_score < 0
        stats.add_rejected(category, is_blocked)
        qualified_mask.append(False)

df = df[qualified_mask]
```

Add helper function for rejection categorization:
```python
def categorize_rejection(result: ScoringResult) -> str:
    """Categorize a rejection reason for statistics."""
    if result.company_score < 0:
        return "company_blocklist"

    if not result.reasons:
        return "unknown"

    reason = result.reasons[0].lower()

    if "missing required" in reason or "no description" in reason:
        return "no_solar_context"

    if "excluded" in reason:
        if any(x in reason for x in ["installer", "stringer", "roofer", "foreman", "crew"]):
            return "exclusions.installer"
        if any(x in reason for x in ["interconnection", "grid", "protection", "metering"]):
            return "exclusions.utility"
        if any(x in reason for x in ["cadence", "synopsys", "mentor", "eda", "asic", "verilog"]):
            return "exclusions.eda_tools"
        if any(x in reason for x in ["satellite", "spacecraft", "orbit", "rocket"]):
            return "exclusions.aerospace"
        if any(x in reason for x in ["tennis", "racquet", "badminton"]):
            return "exclusions.tennis"
        return "exclusions.other"

    return "below_threshold"
```

Return stats from the function - change signature to return `tuple[pd.DataFrame, FilterStats]`:
```python
def scrape_solar_jobs() -> tuple[pd.DataFrame, FilterStats]:
```

Update return statements:
- Empty case: `return pd.DataFrame(), FilterStats()`
- Normal case: `return df, stats`
  </action>
  <verify>
Test with a small mock to verify stats collection pattern works:
```bash
python -c "
from scraper import score_job, FilterStats, categorize_rejection
result = score_job('Solar Designer using Helioscope for PV design')
print(f'qualified={result.qualified}, reasons={result.reasons[:2]}')
"
```
Should show qualified=True with tier1 reason.
  </verify>
  <done>scrape_solar_jobs() collects FilterStats during filtering and returns (DataFrame, FilterStats) tuple.</done>
</task>

<task type="auto">
  <name>Task 3: Add print_filter_stats and wire to main</name>
  <files>scraper.py</files>
  <action>
Add print_filter_stats() function near the end of scraper.py (before main):

```python
def print_filter_stats(stats: FilterStats) -> None:
    """Print human-readable filter statistics."""
    print()
    print("=" * 50)
    print("FILTER STATISTICS")
    print("=" * 50)
    print(f"Total processed:  {stats.total_processed}")
    if stats.total_processed > 0:
        print(f"Qualified:        {stats.total_qualified} ({stats.pass_rate:.1f}%)")
        print(f"Rejected:         {stats.total_rejected} ({100 - stats.pass_rate:.1f}%)")
    else:
        print("Qualified:        0")
        print("Rejected:         0")

    if stats.company_blocked > 0:
        print(f"\nCompany blocklist: {stats.company_blocked}")

    if stats.rejection_categories:
        print("\nTop rejection reasons:")
        for category, count in stats.rejection_categories.most_common(5):
            print(f"  {count:4d} | {category}")

    if stats.qualification_tiers:
        print("\nQualification by tier:")
        for tier, count in sorted(stats.qualification_tiers.items()):
            print(f"  {tier}: {count}")
    print("=" * 50)
```

Update main() to:
1. Receive stats from scrape_solar_jobs()
2. Print stats before saving

Change in main():
```python
# Scrape jobs
raw_jobs, stats = scrape_solar_jobs()

# ... existing code ...

# Print filter statistics
print_filter_stats(stats)

# Save to CSV
# ... existing code ...
```
  </action>
  <verify>
Run with dry test (won't actually scrape, but verifies syntax):
```bash
python -c "
from scraper import FilterStats, print_filter_stats
stats = FilterStats()
stats.add_qualified('tier1')
stats.add_qualified('tier2')
stats.add_rejected('no_solar_context', False)
stats.add_rejected('company_blocklist', True)
print_filter_stats(stats)
"
```
Should print formatted statistics table with 2 qualified, 2 rejected, tier breakdown.
  </verify>
  <done>print_filter_stats() function exists and main() calls it after scraping.</done>
</task>

</tasks>

<verification>
Overall phase verification:
1. FilterStats dataclass exists with proper Counter fields
2. scrape_solar_jobs() returns tuple (DataFrame, FilterStats)
3. Stats are collected during filtering loop
4. Rejection reasons are categorized properly
5. print_filter_stats() displays human-readable output
6. main() wires everything together

Run evaluation to verify no regressions:
```bash
python evaluate.py data/golden/golden-test-set.json
```
Expected: 100% precision, 75% recall (unchanged from Phase 3)
</verification>

<success_criteria>
- [ ] FilterStats dataclass tracks total_processed, total_qualified, total_rejected
- [ ] FilterStats uses Counter for rejection_categories and qualification_tiers
- [ ] scrape_solar_jobs() returns (DataFrame, FilterStats) tuple
- [ ] Rejection reasons categorized to config section names
- [ ] print_filter_stats() shows pass rate, top rejections, tier distribution
- [ ] main() calls print_filter_stats() after scraping
- [ ] All existing tests pass (evaluate.py)
- [ ] QUAL-01 requirement satisfied: "Each run logs filter statistics"
</success_criteria>

<output>
After completion, create `.planning/phases/04-quality-instrumentation/04-01-SUMMARY.md`
</output>
